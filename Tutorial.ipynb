{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE    \n",
    "\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hoped for Mia to have some peace in this book, but her story is so real and raw.  Broken World was so touching and emotional because you go from Mia's trauma to her trying to cope.  I love the way the story displays how there is no \"just bouncing back\" from being sexually assaulted.  Mia showed us how those demons come for you every day and how sometimes they best you. I was so in the moment with Broken World and hurt with Mia because she was surrounded by people but so alone and I understood her feelings.  I found myself wishing I could give her some of my courage and strength or even just to be there for her.  Thank you Lizzy for putting a great character's voice on a strong subject and making it so that other peoples story may be heard through Mia's.\n",
      "5.0\n",
      "POSITIVE\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = './data/sentiment/books_small_10000.json'\n",
    "\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    #print(f)\n",
    "    for line in f:\n",
    "        #print(line)\n",
    "        #break\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "        \n",
    "print(reviews[5].text)\n",
    "print(reviews[5].score)\n",
    "print(reviews[5].sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "train_container = ReviewContainer(training)\n",
    "\n",
    "test_container = ReviewContainer(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning, packing for and setting up a proper camp site is getting to be a dying art. There's a lot to it that modern folks never think about, and as a result, head out for a week of camping with a cheap tent, flimsy air mattress and grossly inadequate food and equipment and are perfectly miserable. My Dad, old curmudgeon that he was, used to take us cross-country with a cardboard box with a couple frying pans, Dutch oven and a coffee pot, and a couple air mattresses. That was HIS idea of &#34;camping&#34;, when he was too cheap to pay $11 a night for a motel room. Mr. Hall gives you the real-lowdown on everything you need to know about proper equipment, planning for your trip, what food to take, how to choose the proper equipment, and gives some good, easy recipes. This is all given in down-to-earth language,, spoken from one whose learned it all the hard way, apparently. As someone who finally got the knack of cooking everything from a respectable beef stew to a pretty tasty dump cake to biscuits in a Dutch oven. it's well worth acquiring the knack to be a &#34;Happy Camper&#34; because there is no where you and your family will have more fun for less money, providing you are properly prepared and equipped.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#TfidfVectorizer=>Term Frequency inverse document frequency\n",
    "\n",
    "# This book is great !\n",
    "# This book was so bad\n",
    "#This book is great was so bad\n",
    "#[1,    1    1   1   0    0  0]=>stmt1\n",
    "#[1,    1    0   0   1    1  1]=>stmt2\n",
    "\n",
    "vectorizer = TfidfVectorizer()#CountVectorizer()#\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '01',\n",
       " '04',\n",
       " '10',\n",
       " '100',\n",
       " '101',\n",
       " '11',\n",
       " '114',\n",
       " '115',\n",
       " '119',\n",
       " '12',\n",
       " '120the',\n",
       " '128532',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '143',\n",
       " '15',\n",
       " '150',\n",
       " '154',\n",
       " '157',\n",
       " '16',\n",
       " '164',\n",
       " '16th',\n",
       " '17',\n",
       " '175',\n",
       " '18',\n",
       " '1800s',\n",
       " '1885',\n",
       " '1887',\n",
       " '1896',\n",
       " '19',\n",
       " '1920',\n",
       " '1923',\n",
       " '1936',\n",
       " '1948',\n",
       " '1954',\n",
       " '1960s',\n",
       " '1962',\n",
       " '1967',\n",
       " '1982',\n",
       " '1987',\n",
       " '1992',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2016',\n",
       " '203',\n",
       " '20th',\n",
       " '21',\n",
       " '210',\n",
       " '21st',\n",
       " '23',\n",
       " '233',\n",
       " '237',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '254',\n",
       " '26',\n",
       " '268',\n",
       " '27',\n",
       " '288',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '30yrs',\n",
       " '33',\n",
       " '34',\n",
       " '345',\n",
       " '35',\n",
       " '37',\n",
       " '390',\n",
       " '39clues',\n",
       " '3can',\n",
       " '3rd',\n",
       " '3so',\n",
       " '40',\n",
       " '400',\n",
       " '40am',\n",
       " '421',\n",
       " '45pm',\n",
       " '4th',\n",
       " '50',\n",
       " '50s',\n",
       " '53',\n",
       " '5color',\n",
       " '5th',\n",
       " '5that',\n",
       " '60',\n",
       " '62',\n",
       " '630',\n",
       " '65',\n",
       " '70',\n",
       " '700',\n",
       " '75',\n",
       " '7am',\n",
       " '7th',\n",
       " '80',\n",
       " '8211',\n",
       " '8212',\n",
       " '8216',\n",
       " '8217',\n",
       " '8220',\n",
       " '8221',\n",
       " '8230',\n",
       " '85',\n",
       " '8th',\n",
       " '90',\n",
       " '90s',\n",
       " '936976',\n",
       " '95',\n",
       " '96',\n",
       " '9679',\n",
       " '978',\n",
       " '99',\n",
       " '9th',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'aaron',\n",
       " 'aback',\n",
       " 'abandoned',\n",
       " 'abbott',\n",
       " 'abbreviations',\n",
       " 'abby',\n",
       " 'abdullah',\n",
       " 'abetted',\n",
       " 'abiding',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abject',\n",
       " 'able',\n",
       " 'abort',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abram',\n",
       " 'abrubtly',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absburg',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'aca',\n",
       " 'academic',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accept',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accidentally',\n",
       " 'accidents',\n",
       " 'accompany',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounts',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'acerbic',\n",
       " 'ache',\n",
       " 'achieve',\n",
       " 'achievements',\n",
       " 'acknowledge',\n",
       " 'acknowledging',\n",
       " 'acne',\n",
       " 'acquiring',\n",
       " 'acquisitions',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'actions',\n",
       " 'active',\n",
       " 'activists',\n",
       " 'actor',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acute',\n",
       " 'acv',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapted',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addiction',\n",
       " 'addictions',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addresses',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adjective',\n",
       " 'adjectives',\n",
       " 'adjusting',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admirer',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adobe',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adorned',\n",
       " 'adrianne',\n",
       " 'adrienne',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advantage',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advised',\n",
       " 'advocating',\n",
       " 'affairs',\n",
       " 'affect',\n",
       " 'affectation',\n",
       " 'affection',\n",
       " 'affects',\n",
       " 'affinity',\n",
       " 'affirms',\n",
       " 'affliction',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afforded',\n",
       " 'affording',\n",
       " 'afghanistan',\n",
       " 'afloat',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afterlife',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'afterwords',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agencies',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggie',\n",
       " 'aggravating',\n",
       " 'aggresively',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhmeds',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aided',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aiming',\n",
       " 'air',\n",
       " 'aircraft',\n",
       " 'airhead',\n",
       " 'airing',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airship',\n",
       " 'aisle',\n",
       " 'ak',\n",
       " 'akin',\n",
       " 'alabama',\n",
       " 'alameda',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'alaskan',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alcatraz',\n",
       " 'alchemist',\n",
       " 'alcohol',\n",
       " 'alcoholics',\n",
       " 'alena',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexandria',\n",
       " 'alexx',\n",
       " 'algeria',\n",
       " 'alice',\n",
       " 'alien',\n",
       " 'aliens',\n",
       " 'alisa',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'all15',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiant',\n",
       " 'allegorical',\n",
       " 'allegory',\n",
       " 'allen',\n",
       " 'allergies',\n",
       " 'alley',\n",
       " 'alliance',\n",
       " 'alliances',\n",
       " 'allison',\n",
       " 'allon',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alluded',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alss',\n",
       " 'alter',\n",
       " 'alternate',\n",
       " 'alternating',\n",
       " 'alternative',\n",
       " 'alternativeworldview',\n",
       " 'although',\n",
       " 'altogether',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambition',\n",
       " 'ambitions',\n",
       " 'ambulance',\n",
       " 'ambulatory',\n",
       " 'amen',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americans',\n",
       " 'amery',\n",
       " 'amish',\n",
       " 'among',\n",
       " 'amoral',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amped',\n",
       " 'ample',\n",
       " 'amsterdam',\n",
       " 'amulet',\n",
       " 'amundsen',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'an',\n",
       " 'analyse',\n",
       " 'analysis',\n",
       " 'anastasia',\n",
       " 'ancestor',\n",
       " 'ancestors',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andre',\n",
       " 'andria',\n",
       " 'andthrough',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'anellia',\n",
       " 'angela',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'anglican',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angsty',\n",
       " 'animal',\n",
       " 'animalistic',\n",
       " 'animals',\n",
       " 'anime',\n",
       " 'anita',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'answert',\n",
       " 'anthology',\n",
       " 'anthropological',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'antics',\n",
       " 'antique',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anya',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anywho',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apologize',\n",
       " 'apology',\n",
       " 'apostrophes',\n",
       " 'app',\n",
       " 'appalachian',\n",
       " 'appalling',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appendix',\n",
       " 'appetite',\n",
       " 'appetizers',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'appliances',\n",
       " 'apply',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'appriciate',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'arab',\n",
       " 'arabs',\n",
       " 'arbenz',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'arch',\n",
       " 'archeology',\n",
       " 'archer',\n",
       " 'architecture',\n",
       " 'arcrating',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'argot',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'arguonova',\n",
       " 'arials',\n",
       " 'arisen',\n",
       " 'arising',\n",
       " 'arizona',\n",
       " 'armature',\n",
       " 'armed',\n",
       " 'arms',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'arranges',\n",
       " 'arresting',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arrowhead',\n",
       " 'art',\n",
       " 'artemis',\n",
       " 'arthurian',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'artifice',\n",
       " 'artificially',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artists',\n",
       " 'artwork',\n",
       " 'arvinthis',\n",
       " 'as',\n",
       " 'ascendentsun',\n",
       " 'ascertain',\n",
       " 'ascertained',\n",
       " 'ashamed',\n",
       " 'ashleytabby',\n",
       " 'ashton',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'asleep',\n",
       " 'asparagus',\n",
       " 'aspbergers',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassinate',\n",
       " 'assassins',\n",
       " 'asserts',\n",
       " 'assessment',\n",
       " 'assets',\n",
       " 'assiduously',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assimilate',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assistants',\n",
       " 'assorted',\n",
       " 'assumed',\n",
       " 'assumedly',\n",
       " 'assuming',\n",
       " 'assumptions',\n",
       " 'assured',\n",
       " 'asteroid',\n",
       " 'astonishing',\n",
       " 'astronomy',\n",
       " 'asylum',\n",
       " 'at',\n",
       " 'ate',\n",
       " 'atheists',\n",
       " 'athletic',\n",
       " 'athletics',\n",
       " 'atlas',\n",
       " 'atmospheric',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attackers',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attemp',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attest',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attorney',\n",
       " 'attorneys',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attraction',\n",
       " 'attractive',\n",
       " 'atv',\n",
       " 'atwood',\n",
       " 'aubrey',\n",
       " 'audacity',\n",
       " 'audible',\n",
       " 'audience',\n",
       " 'audio',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'aunts',\n",
       " 'aura',\n",
       " 'aurhor',\n",
       " 'austen',\n",
       " 'australia',\n",
       " 'authentic',\n",
       " 'author',\n",
       " 'authors',\n",
       " 'autism',\n",
       " 'autobiography',\n",
       " 'autocomplete',\n",
       " 'automatically',\n",
       " 'avail',\n",
       " 'available',\n",
       " 'avalanche',\n",
       " 'avenues',\n",
       " 'average',\n",
       " 'averages',\n",
       " 'avert',\n",
       " 'aviation',\n",
       " 'avid',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'await',\n",
       " 'awaiting',\n",
       " 'awakening',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awww',\n",
       " 'ayn',\n",
       " 'az',\n",
       " 'babble',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babygirl',\n",
       " 'back',\n",
       " 'backed',\n",
       " 'backers',\n",
       " 'backfire',\n",
       " 'backfires',\n",
       " 'background',\n",
       " 'backing',\n",
       " 'backstories',\n",
       " 'backstory',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baddie',\n",
       " 'badly',\n",
       " 'baffled',\n",
       " 'bafflingly',\n",
       " 'bag',\n",
       " 'bagel',\n",
       " 'baggage',\n",
       " 'baked',\n",
       " 'baker',\n",
       " 'baking',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'ball',\n",
       " 'ballad',\n",
       " 'ballads',\n",
       " 'balls',\n",
       " 'banal',\n",
       " 'band',\n",
       " 'bands',\n",
       " 'bandwidth',\n",
       " 'bang',\n",
       " 'bank',\n",
       " 'banking',\n",
       " 'bankrupt',\n",
       " 'banks',\n",
       " 'banter',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barbara',\n",
       " 'barbarism',\n",
       " 'barbour',\n",
       " 'bare',\n",
       " 'bared',\n",
       " 'barely',\n",
       " 'barey',\n",
       " 'bargain',\n",
       " 'baring',\n",
       " 'barker',\n",
       " 'barn',\n",
       " 'barnabas',\n",
       " 'baron',\n",
       " 'barony',\n",
       " 'barred',\n",
       " 'barriers',\n",
       " 'bartel',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'bashes',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basics',\n",
       " 'basketball',\n",
       " 'bass',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathroom',\n",
       " 'bathtub',\n",
       " 'batman',\n",
       " 'batter',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battleships',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bayou',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " 'bdsm',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'bearing',\n",
       " 'bears',\n",
       " 'bearskin',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beats',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beaver',\n",
       " 'became',\n",
       " 'becasue',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'bedford',\n",
       " 'beef',\n",
       " 'beefcake',\n",
       " 'been',\n",
       " 'beenextremely',\n",
       " 'beets',\n",
       " 'before',\n",
       " 'began',\n",
       " 'beggar',\n",
       " 'beggars',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginner',\n",
       " 'beginners',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behavioural',\n",
       " 'behind',\n",
       " 'behold',\n",
       " 'being',\n",
       " 'beings',\n",
       " 'belabor',\n",
       " 'belabored',\n",
       " 'belgian',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'beliefs',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believeable',\n",
       " 'believed',\n",
       " 'believers',\n",
       " 'believes',\n",
       " 'believing',\n",
       " 'belittles',\n",
       " 'belittling',\n",
       " 'belives',\n",
       " 'bella',\n",
       " 'belle',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belongs',\n",
       " 'below',\n",
       " 'bemoans',\n",
       " 'ben',\n",
       " 'bender',\n",
       " 'beneficiaries',\n",
       " 'beneficiary',\n",
       " 'benefit',\n",
       " 'benefits',\n",
       " 'benefitted',\n",
       " 'benjamin',\n",
       " 'bent',\n",
       " 'bernsenauthor',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'beta',\n",
       " 'betcha',\n",
       " 'beth',\n",
       " 'betray',\n",
       " 'betrayal',\n",
       " 'bets',\n",
       " 'better',\n",
       " 'betteralso',\n",
       " 'bettie',\n",
       " 'betting',\n",
       " 'between',\n",
       " 'beverly',\n",
       " 'beware',\n",
       " 'bey',\n",
       " 'beyond',\n",
       " 'bff',\n",
       " 'bias',\n",
       " 'bible',\n",
       " 'biblical',\n",
       " 'biblically',\n",
       " 'bibliography',\n",
       " 'bickering',\n",
       " 'big',\n",
       " 'bigfoot',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigshot',\n",
       " 'biker',\n",
       " 'bikers',\n",
       " 'biking',\n",
       " 'bill',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'biography',\n",
       " 'biological',\n",
       " 'biology',\n",
       " 'biopsies',\n",
       " 'bird',\n",
       " 'birdhouse',\n",
       " 'birdhouses',\n",
       " 'birds',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'births',\n",
       " 'biscuit',\n",
       " 'biscuits',\n",
       " 'bishop',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'bites',\n",
       " 'biting',\n",
       " 'bitingly',\n",
       " 'bits',\n",
       " 'bitten',\n",
       " 'bizarre',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackjack',\n",
       " 'blackmail',\n",
       " 'blackthorn',\n",
       " 'blah',\n",
       " 'blaire',\n",
       " 'blake',\n",
       " 'blakely',\n",
       " 'blame',\n",
       " 'blaming',\n",
       " 'bland',\n",
       " 'blankly',\n",
       " 'blas',\n",
       " 'blatant',\n",
       " 'blatantly',\n",
       " 'blaze',\n",
       " 'bleckkkk',\n",
       " 'blessed',\n",
       " 'blessing',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindly',\n",
       " 'blip',\n",
       " 'blissful',\n",
       " 'blitzing',\n",
       " 'bloated',\n",
       " 'blockbuster',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blogging',\n",
       " 'blogs',\n",
       " 'blood',\n",
       " 'bloodsucking',\n",
       " 'bloody',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blubber',\n",
       " 'blud',\n",
       " 'bludgeoned',\n",
       " 'blue',\n",
       " 'blueberry',\n",
       " 'bluegrass',\n",
       " 'bluntly',\n",
       " 'blurb',\n",
       " 'blurbs',\n",
       " 'blushing',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarder',\n",
       " 'boarding',\n",
       " 'boards',\n",
       " 'boasted',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'body',\n",
       " 'bogenholm',\n",
       " 'bogged',\n",
       " 'bologna',\n",
       " 'bomb',\n",
       " 'bombarded',\n",
       " 'bombastic',\n",
       " 'bombs',\n",
       " 'bona',\n",
       " 'bond',\n",
       " 'bondage',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'bono',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'bookkeeper',\n",
       " 'bookkeeping',\n",
       " 'bookland',\n",
       " 'booklet',\n",
       " 'books',\n",
       " 'bookstore',\n",
       " 'bookstores',\n",
       " 'bookwerewolves',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(872, (872, 8906))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#SVM=>Support Vector Machine\n",
    "\n",
    "clf_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_svm.predict(test_x_vectors[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len(train_y),train_x_vectors.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf_dec = DecisionTreeClassifier()\n",
    "clf_dec.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_dec.predict(test_x_vectors[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-4fb2d1cc0321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclf_gnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf_gnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\shree\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m     75\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shree\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shree\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    509\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\shree\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    307\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_gnb.fit(train_x_vectors.todense(), train_y)\n",
    "\n",
    "clf_gnb.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_log = LogisticRegression()\n",
    "clf_log.fit(train_x_vectors, train_y)\n",
    "\n",
    "clf_log.predict(test_x_vectors[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6754807692307693\n",
      "0.5048076923076923\n",
      "0.8052884615384616\n"
     ]
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "print(clf_svm.score(test_x_vectors, test_y))\n",
    "print(clf_dec.score(test_x_vectors, test_y))\n",
    "#print(clf_gnb.score(test_x_vectors, test_y))\n",
    "print(clf_log.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shree\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.80291971, 0.        , 0.80760095])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 Scores\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#f1_score(test_y, clf_svm.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])\n",
    "f1_score(test_y, clf_log.predict(test_x_vectors), average=None, labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, \n",
    "                                                                        Sentiment.NEGATIVE])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = ['very fun', \"bad book do not buy\", 'horrible waste of time']\n",
    "new_test = vectorizer.transform(test_set)\n",
    "\n",
    "clf_svm.predict(new_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning our model (with Grid Search)\n",
    "\n",
    "GridSearchCV implements a “fit” and a “score” method. It also implements “predict”, “predict_proba”, “decision_function”, “transform” and “inverse_transform” if they are implemented in the estimator used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(train_x_vectors, train_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "print(clf.score(test_x_vectors, test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./models/sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/entiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this book and the previous books in this series. It brings out every emotion you can think of. I look forward to reading more books by this author.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_x[0])\n",
    "\n",
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "           fit_intercept=True, max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "           penalty=None, random_state=0, shuffle=True, tol=0.001,\n",
       "           validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(train_x_vectors, train_y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
